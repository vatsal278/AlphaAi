{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "images = np.load(\"images.npy\")\n",
    "labels = np.load(\"labels.npy\")\n",
    "labels = labels.reshape(-1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.1)\n",
    "train_gen.fit(x_train)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen.fit(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 478, 638, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 478, 638, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 239, 319, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 237, 317, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 237, 317, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 118, 158, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 596608)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                38182976  \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 38,193,185\n",
      "Trainable params: 38,193,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(480,640,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "#model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='mae',\n",
    "              optimizer=keras.optimizers.Adam(lr=1e-6),\n",
    "              metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 38s 202ms/step - loss: 24.5453 - mse: 682.8593 - val_loss: 7.2957 - val_mse: 88.2280\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 27s 180ms/step - loss: 7.3158 - mse: 83.7418 - val_loss: 5.7544 - val_mse: 55.5514\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 27s 180ms/step - loss: 6.9754 - mse: 76.6208 - val_loss: 6.5996 - val_mse: 66.3875\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 27s 181ms/step - loss: 6.7554 - mse: 73.6098 - val_loss: 6.9304 - val_mse: 76.5462\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 27s 181ms/step - loss: 7.1922 - mse: 81.5756 - val_loss: 6.1435 - val_mse: 58.7912\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 27s 181ms/step - loss: 7.0075 - mse: 74.0799 - val_loss: 6.0873 - val_mse: 62.3561\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 27s 181ms/step - loss: 6.8560 - mse: 74.5545 - val_loss: 6.3372 - val_mse: 62.0133\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 6.7818 - mse: 72.9110 - val_loss: 5.7527 - val_mse: 53.5089\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 6.6309 - mse: 69.2659 - val_loss: 6.5444 - val_mse: 67.5394\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 6.8814 - mse: 72.8643 - val_loss: 6.3167 - val_mse: 61.3631\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 6.7090 - mse: 69.4433 - val_loss: 6.0138 - val_mse: 54.9751\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 27s 182ms/step - loss: 6.7835 - mse: 72.2617 - val_loss: 6.5561 - val_mse: 63.4865\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 28s 183ms/step - loss: 6.8139 - mse: 74.7296 - val_loss: 6.7780 - val_mse: 70.6601\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 6.5611 - mse: 67.4681 - val_loss: 6.0210 - val_mse: 62.2548\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 6.2409 - mse: 61.0061 - val_loss: 6.4397 - val_mse: 62.8367\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 6.6119 - mse: 68.2980 - val_loss: 6.0843 - val_mse: 58.2488\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 6.6286 - mse: 69.1660 - val_loss: 6.1900 - val_mse: 61.0007\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 6.4248 - mse: 67.8962 - val_loss: 5.7980 - val_mse: 52.9841\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 6.5278 - mse: 65.6223 - val_loss: 5.5241 - val_mse: 49.4294\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 6.6517 - mse: 67.6902 - val_loss: 6.0069 - val_mse: 59.3026\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 6.3476 - mse: 64.5002 - val_loss: 6.0366 - val_mse: 57.7002\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 6.4002 - mse: 64.1429 - val_loss: 6.0794 - val_mse: 59.4203\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 6.5777 - mse: 67.6302 - val_loss: 5.7293 - val_mse: 51.9251\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 6.3308 - mse: 62.3309 - val_loss: 5.7100 - val_mse: 52.3849\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 28s 184ms/step - loss: 6.2992 - mse: 63.2510 - val_loss: 5.3352 - val_mse: 45.6057\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 6.2589 - mse: 61.1212 - val_loss: 5.3990 - val_mse: 46.8732\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 29s 190ms/step - loss: 5.9469 - mse: 56.6063 - val_loss: 5.4859 - val_mse: 48.3639\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 6.4845 - mse: 65.6889 - val_loss: 5.4583 - val_mse: 49.8458\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 6.1742 - mse: 60.7012 - val_loss: 5.4463 - val_mse: 46.1240\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.8276 - mse: 54.7350 - val_loss: 5.3753 - val_mse: 47.4692\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 6.1463 - mse: 60.4731 - val_loss: 5.5049 - val_mse: 50.6898\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.8042 - mse: 52.3315 - val_loss: 5.5244 - val_mse: 47.7794\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 6.0857 - mse: 58.9074 - val_loss: 5.7729 - val_mse: 52.1402\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 6.0712 - mse: 57.8391 - val_loss: 5.4424 - val_mse: 46.0062\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 6.0431 - mse: 58.4150 - val_loss: 5.2842 - val_mse: 45.0385\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.7571 - mse: 53.7681 - val_loss: 5.3257 - val_mse: 44.1726\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 5.6971 - mse: 51.8361 - val_loss: 5.4862 - val_mse: 48.6925\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 5.7569 - mse: 52.4952 - val_loss: 4.9110 - val_mse: 41.8593\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.7274 - mse: 52.4379 - val_loss: 5.1664 - val_mse: 45.5979\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.8774 - mse: 52.6995 - val_loss: 5.2887 - val_mse: 44.4817\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.5854 - mse: 51.6300 - val_loss: 5.0569 - val_mse: 40.1098\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.7088 - mse: 53.1339 - val_loss: 5.2077 - val_mse: 43.9196\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.5013 - mse: 47.1542 - val_loss: 5.3537 - val_mse: 45.9770\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 5.7426 - mse: 53.2662 - val_loss: 5.1527 - val_mse: 42.3310\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 5.4023 - mse: 46.7810 - val_loss: 5.2219 - val_mse: 42.3103\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 5.5526 - mse: 50.1358 - val_loss: 4.3653 - val_mse: 31.6551\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 5.6623 - mse: 52.3772 - val_loss: 4.8438 - val_mse: 40.5886\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 29s 190ms/step - loss: 5.5924 - mse: 49.2194 - val_loss: 5.3316 - val_mse: 45.4078\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 5.3388 - mse: 46.3120 - val_loss: 4.9560 - val_mse: 39.1865\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 27s 183ms/step - loss: 5.4865 - mse: 47.6233 - val_loss: 4.7638 - val_mse: 39.9607\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 28s 185ms/step - loss: 5.3633 - mse: 47.2177 - val_loss: 4.8368 - val_mse: 39.5875\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 5.4478 - mse: 49.7253 - val_loss: 4.4374 - val_mse: 33.0781\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 5.3418 - mse: 45.4159 - val_loss: 4.8795 - val_mse: 39.7499\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 5.3598 - mse: 45.9332 - val_loss: 4.1988 - val_mse: 28.8357\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 5.3737 - mse: 45.9570 - val_loss: 4.7937 - val_mse: 37.0566\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 5.3034 - mse: 44.2224 - val_loss: 4.5559 - val_mse: 33.7102\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 5.2005 - mse: 42.5729 - val_loss: 4.3246 - val_mse: 32.2623\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 28s 188ms/step - loss: 5.1552 - mse: 42.2066 - val_loss: 4.7443 - val_mse: 35.4540\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.2348 - mse: 45.0788 - val_loss: 4.5586 - val_mse: 35.6554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.0453 - mse: 40.4387 - val_loss: 4.5448 - val_mse: 33.1500\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 5.3974 - mse: 46.8814 - val_loss: 4.3367 - val_mse: 31.8184\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 5.1336 - mse: 41.7607 - val_loss: 4.3450 - val_mse: 29.7205\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.2236 - mse: 43.9110 - val_loss: 4.8361 - val_mse: 38.8658\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.1696 - mse: 42.4474 - val_loss: 4.1324 - val_mse: 28.6136\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.1151 - mse: 41.9587 - val_loss: 4.2057 - val_mse: 28.6733\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 5.0301 - mse: 40.4595 - val_loss: 3.9799 - val_mse: 28.2471\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 4.8874 - mse: 39.0797 - val_loss: 4.2569 - val_mse: 30.8123\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 4.9811 - mse: 39.1252 - val_loss: 3.9799 - val_mse: 26.7556\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 5.0533 - mse: 41.3252 - val_loss: 4.0515 - val_mse: 27.5436\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.9444 - mse: 38.0731 - val_loss: 4.1830 - val_mse: 28.9689\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.9962 - mse: 39.5637 - val_loss: 3.7246 - val_mse: 23.0768\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 4.9505 - mse: 37.9316 - val_loss: 4.2549 - val_mse: 28.9983\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 5.0391 - mse: 41.9718 - val_loss: 4.1477 - val_mse: 28.7364\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 4.8898 - mse: 38.8396 - val_loss: 4.0344 - val_mse: 26.5649\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 28s 187ms/step - loss: 4.9220 - mse: 40.5925 - val_loss: 4.1892 - val_mse: 28.5227\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 28s 190ms/step - loss: 5.0213 - mse: 40.5622 - val_loss: 3.9232 - val_mse: 26.1294\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 4.7515 - mse: 36.3063 - val_loss: 3.7218 - val_mse: 22.3287\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 4.8288 - mse: 36.8734 - val_loss: 4.0418 - val_mse: 27.4302\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 29s 190ms/step - loss: 4.7780 - mse: 37.5753 - val_loss: 3.6910 - val_mse: 21.4826\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 28s 183ms/step - loss: 4.7864 - mse: 38.1270 - val_loss: 3.9162 - val_mse: 25.9840\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 28s 186ms/step - loss: 4.6644 - mse: 35.6020 - val_loss: 3.6580 - val_mse: 22.4014\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 28s 189ms/step - loss: 4.6096 - mse: 34.8486 - val_loss: 3.8189 - val_mse: 23.3228\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 4.5356 - mse: 33.5666 - val_loss: 3.6891 - val_mse: 21.5190\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.5627 - mse: 33.2818 - val_loss: 3.8884 - val_mse: 24.4078\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 4.7669 - mse: 37.0664 - val_loss: 3.7608 - val_mse: 21.8739\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 29s 192ms/step - loss: 4.5210 - mse: 32.8304 - val_loss: 3.5897 - val_mse: 20.6906\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 4.5475 - mse: 33.1408 - val_loss: 3.8697 - val_mse: 25.4297\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 4.6587 - mse: 34.6738 - val_loss: 3.6811 - val_mse: 22.3035\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.4229 - mse: 33.0719 - val_loss: 3.7640 - val_mse: 23.4016\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.4131 - mse: 31.0755 - val_loss: 3.3857 - val_mse: 18.9862\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 29s 191ms/step - loss: 4.6416 - mse: 33.1373 - val_loss: 3.5393 - val_mse: 20.6580\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.4640 - mse: 31.8534 - val_loss: 3.3347 - val_mse: 18.6905\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 4.6712 - mse: 34.6306 - val_loss: 3.2413 - val_mse: 16.6312\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 4.5168 - mse: 33.1045 - val_loss: 3.8229 - val_mse: 23.8023\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 4.5358 - mse: 33.3763 - val_loss: 3.6720 - val_mse: 22.0596\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 29s 193ms/step - loss: 4.3040 - mse: 29.7608 - val_loss: 3.3021 - val_mse: 17.3991\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 29s 195ms/step - loss: 4.4138 - mse: 31.2928 - val_loss: 3.4579 - val_mse: 19.0456\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 29s 196ms/step - loss: 4.3482 - mse: 29.9357 - val_loss: 3.1841 - val_mse: 16.2128\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 29s 194ms/step - loss: 4.3594 - mse: 30.9343 - val_loss: 3.3610 - val_mse: 17.6382\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 30s 196ms/step - loss: 4.3840 - mse: 32.4592 - val_loss: 3.2579 - val_mse: 18.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c9785918e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen.flow(x_train, y_train, batch_size=12), validation_data=test_gen.flow(x_test, y_test, batch_size=4), validation_steps=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('crowd_count2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.707668 31.713137 30.586946 27.455986 35.73194  35.918125 34.678745\n",
      " 27.561352 30.447775 28.126816 33.162247 29.705233 26.391975 30.514221\n",
      " 35.960274 29.490135 33.828186 26.22399  22.4903   32.680225 24.696049\n",
      " 32.47279  23.605692 27.571215 27.144897 34.293583 20.65748  34.578262\n",
      " 27.228312 28.680841 29.876976 30.565207]\n",
      "[24 30 31 22 40 37 44 30 36 26 37 34 27 38 48 30 36 27 18 35 25 34 21 24\n",
      " 26 36 20 43 35 30 29 27]\n",
      "[29.496935 34.981716 32.64972  30.365482 26.372574 27.716087 31.779835\n",
      " 33.12254  25.850018 18.72654  33.70236  21.585075 29.641016 30.620518\n",
      " 29.372032 28.003736 38.263233 37.656624 22.81642  25.631046 35.62875\n",
      " 26.498896 31.378489 24.435043 23.980862 35.02301  36.58345  29.751646\n",
      " 37.860146 29.654575 35.43     33.53514 ]\n",
      "[29 41 36 24 28 24 32 33 21 17 46 23 29 29 31 25 39 46 22 21 42 30 34 28\n",
      " 25 38 43 29 45 28 36 36]\n",
      "[29.621733 31.055136 33.655407 24.023262 26.274147 28.263834 29.823872\n",
      " 34.03319  27.937086 29.68349  30.447302 22.680525 29.095053 30.69984\n",
      " 33.13983  27.864155 31.96057  28.173134 33.960766 32.205055 24.010633\n",
      " 27.458748 26.183178 23.255531 33.125317 31.53324  27.066591 27.322662\n",
      " 34.600746 24.830286 36.69634  21.220924]\n",
      "[31 29 34 27 23 28 27 40 28 28 32 21 28 42 34 25 34 32 39 41 32 30 24 18\n",
      " 41 40 26 27 32 24 43 19]\n",
      "[31.35169  31.771965 22.759872 28.966448 25.173168 31.140501 28.120913\n",
      " 30.80816  26.50038  36.307575 31.774185 26.975399 28.02084  35.776463\n",
      " 26.23874  35.190502 30.335995 30.007195 26.315321 29.142542 34.84229\n",
      " 30.2986   27.459972 29.533003 28.309633 33.588444 29.098623 35.669415\n",
      " 33.03641  30.214165 35.388638 32.39459 ]\n",
      "[33 32 19 32 22 31 29 37 28 45 33 27 28 47 22 42 30 26 23 33 42 27 29 31\n",
      " 29 37 30 41 39 31 43 28]\n",
      "[23.609354 29.656605 35.421585 27.974852 22.66139  26.806917 30.66962\n",
      " 27.207373 31.819181 26.264055 35.165966 23.380394 29.014238 31.934834\n",
      " 27.660254 32.326637 26.03929  30.635849 30.440218 26.48357  27.443592\n",
      " 19.409027 26.389057 24.955679 21.824371 23.913437 24.956654 32.666435\n",
      " 31.735249 29.477453 31.310947 31.193693]\n",
      "[26 33 38 23 20 27 30 22 30 22 42 23 28 32 27 40 28 32 29 26 23 17 24 23\n",
      " 20 19 22 40 30 28 33 30]\n",
      "[35.110954 32.58554  39.48426  27.750391 29.698431 36.222176 32.001446\n",
      " 29.201757 28.508972 25.015774 38.65682  32.125378 34.331966 32.204903\n",
      " 34.5077   29.523561 27.872276 32.255108 29.657804 37.90748  22.931189\n",
      " 25.737463 25.36893  34.32705  29.877832 29.893417 35.547314 30.082079\n",
      " 31.86809  31.378197 30.65414  29.56073 ]\n",
      "[46 32 41 23 35 47 37 34 32 19 47 34 32 36 44 30 26 37 28 46 16 27 29 42\n",
      " 25 33 45 30 36 32 29 38]\n",
      "[30.106276 28.280312 31.416727 37.32286  30.809786 31.054804 30.570314\n",
      " 34.037556]\n",
      "[26 28 29 45 30 30 32 36]\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_gen.flow(x_test, y_test)\n",
    "test_generator.reset()\n",
    "all_labels = []\n",
    "all_pred = []\n",
    "for i in range(len(test_generator)):\n",
    "    x = next(test_generator)\n",
    "    pred_i = model.predict(x[0])[:,0]\n",
    "    labels_i = x[1]\n",
    "    print(pred_i)\n",
    "    print(labels_i)\n",
    "    all_labels.append(labels_i)\n",
    "    all_pred.append(pred_i)\n",
    "\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_pred = np.concatenate(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.144813162242546,\n",
       " 50.710430810377815,\n",
       " 18.040941979238315,\n",
       " 53.606559627373585)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g=plt.scatter(all_labels, all_pred)\n",
    "g.axes.set_yscale('log')\n",
    "g.axes.set_xscale('log')\n",
    "g.axes.set_xlabel('True Values ')\n",
    "g.axes.set_ylabel('Predictions ')\n",
    "g.axes.axis('equal')\n",
    "g.axes.axis('square')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
